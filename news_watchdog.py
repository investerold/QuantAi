import time
import json
import requests
import os
import yfinance as yf
import xml.etree.ElementTree as ET
import re
from datetime import datetime

# ================= CONFIGURATION =================
WATCHLIST = ['HIMS', 'ZETA', 'ODD', 'NVDA', 'TSLA', 'AMD', 'OSCR']
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN')
TELEGRAM_CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')
HISTORY_FILE = 'news_history.json'

# âœ… æ”¹ç”¨ 1.5 Flashï¼Œæ¯æ—¥é¡åº¦ (RPD) é€šå¸¸æ˜¯ 1500 æ¬¡ï¼Œé é«˜æ–¼ 2.5 Flash çš„ 50 æ¬¡
# å¦‚æœä½ å …æŒè¦ç”¨ 2.5ï¼Œè«‹è‡ªè¡Œæ”¹å› "gemini-2.5-flash"ï¼Œä½†ä¿è­‰æœƒçˆ†
GEMINI_MODEL = "gemini-2.5-flash-lite"

# åƒåœ¾é—œéµå­—éæ¿¾ (ç¯€çœ API)
IGNORE_KEYWORDS = [
    "class action", "lawsuit", "investigation", "zacks", "motley fool", 
    "shareholder rights", "loss alert", "reminder", "dividend"
]

# ================= FUNCTIONS =================

def load_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, 'r') as f:
                return set(json.load(f))
        except:
            return set()
    return set()

def save_history(history_set):
    # åªä¿ç•™æœ€å¾Œ 500 æ¢è¨˜éŒ„ï¼Œé¿å…æ–‡ä»¶éå¤§
    clean_history = list(history_set)[-500:] 
    with open(HISTORY_FILE, 'w') as f:
        json.dump(clean_history, f, indent=2)

def clean_html(raw_html):
    if not raw_html: return ""
    cleanr = re.compile('<.*?>')
    text = re.sub(cleanr, '', raw_html)
    return text.replace('&nbsp;', ' ').strip()

def is_spam(title):
    """æª¢æŸ¥æ¨™é¡Œæ˜¯å¦åŒ…å«åƒåœ¾é—œéµå­—"""
    title_lower = title.lower()
    for kw in IGNORE_KEYWORDS:
        if kw in title_lower:
            return True
    return False

def send_telegram_message(message):
    if not TELEGRAM_TOKEN or not TELEGRAM_CHAT_ID:
        return
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {
        "chat_id": TELEGRAM_CHAT_ID,
        "text": message,
        "parse_mode": "Markdown",
        "disable_web_page_preview": True
    }
    try:
        requests.post(url, json=payload, timeout=10)
    except Exception as e:
        print(f"Telegram Error: {e}")

def get_google_rss_news(ticker):
    print(f"   ğŸ“¡ Fetching Google RSS for {ticker}...")
    try:
        url = f"https://news.google.com/rss/search?q={ticker}+stock&hl=en-US&gl=US&ceid=US:en"
        headers = {"User-Agent": "Mozilla/5.0"}
        resp = requests.get(url, headers=headers, timeout=10)
        
        if resp.status_code != 200: return []
            
        root = ET.fromstring(resp.content)
        items = []
        for item in root.findall('.//item')[:4]:  # å–å‰ 4 æ¢
            title = item.find('title').text
            link = item.find('link').text
            
            if title and link and not is_spam(title):
                items.append({
                    'title': title, 
                    'link': link, 
                    'source': 'GoogleRSS'
                })
        return items
    except Exception as e:
        print(f"   âŒ RSS Failed: {e}")
        return []

def get_yfinance_news(ticker):
    print(f"   âš ï¸ RSS Empty, trying yfinance for {ticker}...")
    try:
        stock = yf.Ticker(ticker)
        news = stock.news
        formatted_news = []
        for item in news[:3]: 
            title = item.get('title')
            link = item.get('link') or item.get('url')
            if title and link and not is_spam(title):
                formatted_news.append({
                    'title': title,
                    'link': link,
                    'source': 'Yahoo'
                })
        return formatted_news
    except:
        return []

def call_gemini_batch(ticker, news_items):
    """
    æ‰¹æ¬¡è™•ç†ï¼šå°‡è©²è‚¡ç¥¨çš„æ‰€æœ‰æ–°æ–°èæ‰“åŒ…æˆä¸€å€‹ Prompt ç™¼é€ã€‚
    ç¯€çœ API Call æ¬¡æ•¸ (N -> 1)ã€‚
    """
    if not GEMINI_API_KEY: return None

    # æ§‹å»º Prompt
    news_text = ""
    for idx, item in enumerate(news_items, 1):
        news_text += f"{idx}. {item['title']} (Link: {item['link']})\n"

    prompt = f"""
    Role: Senior Stock Analyst (Peter Lynch Style).
    Ticker: {ticker}
    
    Here are the latest news headlines:
    {news_text}
    
    Task:
    1. Analyze the aggregate sentiment (Bullish ğŸŸ¢ / Bearish ğŸ”´ / Neutral âšª).
    2. Summarize the MOST critical impact in 1-2 bullet points.
    3. Ignore repetitive noise.
    
    Output Format:
    [Sentiment Icon] {ticker} Update
    â€¢ [Summary of key event]
    """
    
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    
    try:
        response = requests.post(api_url, json=payload, headers={'Content-Type': 'application/json'}, timeout=20)
        
        if response.status_code == 200:
            return response.json()['candidates'][0]['content']['parts'][0]['text'].strip()
        elif response.status_code == 429:
            print(f"      âš ï¸ Quota Limit (429).")
            return "SKIP_QUOTA"
        else:
            print(f"      âŒ API Error {response.status_code}: {response.text}")
            return None
    except Exception as e:
        print(f"      âŒ Connection Error: {e}")
        return None

def main():
    print(f"[{datetime.now()}] Starting Watchdog v9.0 (Batch Mode + 1.5 Flash)...")
    
    history = load_history()
    print(f"Loaded {len(history)} history items.")
    
    new_alerts = 0
    
    for ticker in WATCHLIST:
        print(f"--------------------------------------------------")
        print(f"Checking {ticker}...", end=" ")
        
        # 1. ç²å–æ–°è
        raw_news = get_google_rss_news(ticker)
        if not raw_news:
            raw_news = get_yfinance_news(ticker)
            
        # 2. éæ¿¾å·²è®€æ–°è
        fresh_news = []
        for item in raw_news:
            clean_url = item.get('link').split('?')[0]
            if clean_url not in history:
                fresh_news.append(item)
        
        print(f"Found {len(fresh_news)} NEW items.")
        
        if not fresh_news:
            continue

        # 3. æ‰¹æ¬¡åˆ†æ (Batch Analysis)
        # åªå–å‰ 3 æ¢æœ€æ–°çš„ä¾†åˆ†æï¼Œé¿å… Token éé•·
        target_news = fresh_news[:3]
        
        print(f"   -> Batch analyzing {len(target_news)} items...")
        analysis = call_gemini_batch(ticker, target_news)
        
        if analysis == "SKIP_QUOTA":
            print("      âš ï¸ Quota hit, stopping batch.")
            break
            
        if analysis:
            # æ§‹å»ºæ¶ˆæ¯ï¼šAI åˆ†æ + ä¾†æºéˆæ¥
            links_md = "\n".join([f"[Source {i+1}]({n['link']})" for i, n in enumerate(target_news)])
            msg = f"{analysis}\n\n{links_md}"
            
            send_telegram_message(msg)
            new_alerts += 1
            
            # æ›´æ–°æ­·å²
            for item in target_news:
                history.add(item.get('link').split('?')[0])
                
            # å†·å»æ™‚é–“ï¼šé›–ç„¶ç”¨äº† Batchï¼Œé‚„æ˜¯ä¼‘æ¯ 5 ç§’æ¯”è¼ƒä¿éšª
            time.sleep(5)
        else:
            print("      âŒ AI Analysis Failed")

    save_history(history)
    print(f"--------------------------------------------------")
    print(f"Done. Sent {new_alerts} alerts.")

if __name__ == "__main__":
    main()
